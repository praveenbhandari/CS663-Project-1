<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hybrid Detection System - PCB Defect Detection Project</title>
    <link rel="stylesheet" href="styles.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
</head>
<body>
    <header class="header">
        <nav class="navbar">
            <div class="nav-container">
                <div class="nav-logo">
                    <h1>PCB Defect Detection</h1>
                </div>
                <ul class="nav-menu">
                    <li class="nav-item">
                        <a href="index.html" class="nav-link">Home</a>
                    </li>
                    <li class="nav-item">
                        <a href="intro.html" class="nav-link">Introduction</a>
                    </li>
                    <li class="nav-item">
                        <a href="defects.html" class="nav-link">Common Defects</a>
                    </li>
                    <li class="nav-item">
                        <a href="setup.html" class="nav-link">Camera Setup</a>
                    </li>
                    <li class="nav-item">
                        <a href="opencv.html" class="nav-link">OpenCV Techniques</a>
                    </li>
                    <li class="nav-item">
                        <a href="results.html" class="nav-link">Results & Analysis</a>
                    </li>
                    <li class="nav-item">
                        <a href="machine-learning.html" class="nav-link active">Machine Learning</a>
                    </li>
                    <li class="nav-item">
                        <a href="interactive.html" class="nav-link">Interactive Demo</a>
                    </li>
                    <li class="nav-item">
                        <a href="bibliography.html" class="nav-link">Bibliography</a>
                    </li>
                </ul>
                <div class="hamburger">
                    <span class="bar"></span>
                    <span class="bar"></span>
                    <span class="bar"></span>
                </div>
            </div>
        </nav>
    </header>

    <main class="main-content">
        <div class="progress-bar">
            <div class="progress-fill"></div>
        </div>
        
        <section class="content-header">
            <div class="container">
                <h1>Hybrid Detection System</h1>
                <p>Combining classical computer vision with machine learning for accurate real-time defect detection</p>
            </div>
        </section>

        <div class="content-body">
            <div class="container">

                <section class="audio-narration" style="background: #f8f9fa; padding: 1.5rem; border-radius: 8px; margin-bottom: 2rem; border-left: 4px solid #3498db;">
                    <h3 style="margin-bottom: 1rem; color: #2c3e50;">üîä Audio Narration</h3>
                    <audio controls style="width: 100%;">
                        <source src="audio/machine-learning.mp3" type="audio/mpeg">
                        Your browser does not support the audio element.
                    </audio>
                    <p style="margin-top: 0.5rem; font-size: 0.9rem; color: #666;">Listen to the audio narration for this page</p>
                </section>

                <section class="content-section">
                    <h2>System Overview</h2>
                    <p>This project implements a hybrid detection system combining classical computer vision with machine learning for PCB defect detection. The system detects five defect types: open circuits, short circuits, micro-cracks, missing traces, and geometric errors.</p>
                    
                    <h3>Two-Stage Pipeline</h3>
                    <p>The hybrid system operates in two stages for optimal speed and accuracy:</p>
                    <ul>
                        <li><strong>Stage 1 - Classical CV Pre-screening (0.1 seconds):</strong> OpenCV methods filter 80% of obvious cases using edge detection, morphological operations, HSV segmentation, and template matching.</li>
                        <li><strong>Stage 2 - Deep Learning Verification (0.2-0.5 seconds):</strong> Complex defects undergo CNN analysis using YOLO v8 for localization and U-Net for pixel-level segmentation.</li>
                    </ul>
                    
                    <h3>Performance Achieved</h3>
                    <ul>
                        <li><strong>Classical CV alone:</strong> 78% accuracy</li>
                        <li><strong>Pure ML:</strong> 95% accuracy but too slow for production</li>
                        <li><strong>Hybrid system:</strong> 92% accuracy at 0.2 seconds average‚Äîthe optimal balance</li>
                    </ul>
                    
                    <img src="images/ml-overview-diagram.jpg" alt="Hybrid detection pipeline architecture" class="content-image">
                    <p class="image-caption">Figure 16: Hybrid ML pipeline architecture combining classical CV pre-screening with deep learning verification.</p>
                </section>

                <section class="content-section">
                    <h2>Training Datasets</h2>
                    <p>The system was trained on 3,500+ annotated images from three established benchmark datasets:</p>
                    
                    <h3>1. PCB Defect Dataset (Tang et al., 2023)</h3>
                    <p>1,000+ annotated PCB images covering open circuits, short circuits, and missing traces.</p>
                    
                    <img src="images/tang-dataset-examples.jpg" alt="Examples from Tang et al. PCB defect dataset" class="content-image">
                    <p class="image-caption">Figure 17a: Sample images from Tang et al. dataset showing open circuits, short circuits, and missing traces. Source: PCB defect dataset <a href="bibliography.html#ref1" class="reference-link">[1]</a>.</p>
                    
                    <ul>
                        <li><strong>Size:</strong> 1,000+ images</li>
                        <li><strong>Resolution:</strong> 1024x1024 pixels</li>
                        <li><strong>Defect Types:</strong> Open circuits, short circuits, missing traces</li>
                        <li><strong>Format:</strong> Bounding box annotations</li>
                    </ul>
                    
                    <h3>2. TDD-net Dataset (Ding et al., 2023)</h3>
                    <p>500+ high-resolution images at 2048x2048 for micro-defects under 0.1mm.</p>
                    
                    <img src="images/tdd-dataset-examples.jpg" alt="Examples from TDD-net dataset showing micro-defects" class="content-image">
                    <p class="image-caption">Figure 17b: High-resolution examples from TDD-net dataset showing micro-cracks and tiny defects under 100 micrometers. Source: Tiny defect detection research <a href="bibliography.html#ref2" class="reference-link">[2]</a>.</p>
                    
                    <ul>
                        <li><strong>Size:</strong> 500+ images</li>
                        <li><strong>Resolution:</strong> 2048x2048 pixels</li>
                        <li><strong>Defect Types:</strong> Micro-cracks (10-100 micrometers)</li>
                        <li><strong>Format:</strong> Pixel-level segmentation masks</li>
                    </ul>
                    
                    <h3>3. Industrial PCB Dataset</h3>
                    <p>2,000+ images from real manufacturing conditions with multiple lighting scenarios.</p>
                    
                    <img src="images/industrial-dataset-examples.jpg" alt="Examples from industrial PCB dataset" class="content-image">
                    <p class="image-caption">Figure 17c: Real-world industrial PCB images showing various lighting conditions and board types. Source: Manufacturing inspection data.</p>
                    
                    <ul>
                        <li><strong>Size:</strong> 2,000+ images</li>
                        <li><strong>Resolution:</strong> Variable (512x512 to 2048x2048)</li>
                        <li><strong>Defect Types:</strong> All major defect categories</li>
                        <li><strong>Format:</strong> Mixed annotations (bounding boxes + segmentation)</li>
                    </ul>
                    
                    <h3>Data Preprocessing Pipeline</h3>
                    <p>The data preprocessing pipeline includes:</p>
                    <ul>
                        <li>Image normalization and resizing to standard input dimensions</li>
                        <li>Data augmentation: random rotations, flips, brightness/contrast adjustments</li>
                        <li>Gaussian noise injection for robustness</li>
                        <li>70/15/15 split for training, validation, and test sets with stratification</li>
                    </ul>
                </section>

                <section class="content-section">
                    <h2>System Architecture</h2>
                    <p>The hybrid system uses different techniques based on defect complexity and confidence levels.</p>
                    
                    <h3>Stage 1: Classical CV Pre-screening</h3>
                    <p>Fast filtering methods handle clear cases:</p>
                    <ul>
                        <li><strong>Canny Edge Detection:</strong> Identifies trace boundaries and breaks</li>
                        <li><strong>Morphological Operations:</strong> Analyzes trace width and spacing</li>
                        <li><strong>HSV Segmentation:</strong> Isolates copper traces from substrate</li>
                        <li><strong>Template Matching:</strong> Compares against reference images</li>
                    </ul>
                    <p><strong>Processing Time:</strong> 0.1 seconds | <strong>Filters:</strong> 80% of obvious cases</p>
                    
                    <h3>Stage 2: Deep Learning Verification</h3>
                    <p>Neural networks handle complex defects with lighting variations and alignment issues:</p>
                    
                    <img src="images/cnn-architecture.jpg" alt="Deep learning models for PCB defect detection" class="content-image">
                    <p class="image-caption">Figure 18: Deep learning architecture with ResNet50/EfficientNet backbones for feature extraction.</p>
                    
                    <ul>
                        <li><strong>YOLO v8:</strong> Real-time object detection for defect localization (0.2 seconds, 92% accuracy)</li>
                        <li><strong>U-Net:</strong> Pixel-level segmentation for precise defect boundaries (0.5 seconds, 95% accuracy)</li>
                        <li><strong>Backbone:</strong> ResNet50 or EfficientNet for feature extraction</li>
                    </ul>
                    
                </section>

                <section class="content-section">
                    <h2>Training Methodology</h2>
                    <p>The system was trained using transfer learning and data augmentation techniques to achieve robust performance across all defect types.</p>
                    
                    <h3>Training Strategy</h3>
                    <ul>
                        <li><strong>Transfer Learning:</strong> Pre-trained ResNet50 and EfficientNet backbones fine-tuned on 3,500+ PCB images</li>
                        <li><strong>Data Augmentation:</strong> Random rotations, flips, brightness/contrast adjustments, and Gaussian noise</li>
                        <li><strong>Multi-scale Training:</strong> Multiple resolution inputs for robust scale detection</li>
                        <li><strong>Weighted Sampling:</strong> Addressing class imbalance with inverse frequency weighting</li>
                    </ul>
                    
                    <img src="images/training-process.jpg" alt="Training process for hybrid PCB defect detection" class="content-image">
                    <p class="image-caption">Figure 19: Training pipeline with data preprocessing, model training, and validation phases.</p>
                    
                    <h3>Training Configuration</h3>
                    <ul>
                        <li><strong>Optimizer:</strong> Adam with learning rate 0.001, ReduceLROnPlateau scheduling</li>
                        <li><strong>Loss Functions:</strong> Cross-entropy for classification, Dice + Focal loss for segmentation</li>
                        <li><strong>Batch Size:</strong> 32 images</li>
                        <li><strong>Epochs:</strong> 50-100 with early stopping</li>
                        <li><strong>Regularization:</strong> Weight decay (0.0001), dropout (0.3)</li>
                        <li><strong>Data Split:</strong> 70% training, 15% validation, 15% testing with stratification</li>
                    </ul>
                </section>

                <section class="content-section">
                    <h2>Performance Results</h2>
                    <p>Comprehensive testing demonstrates the effectiveness of the hybrid approach across all defect types and processing speeds.</p>
                    
                    <h3>Evaluation Metrics</h3>
                    <ul>
                        <li><strong>Accuracy:</strong> Overall correct predictions percentage</li>
                        <li><strong>Precision:</strong> Ratio of true positives to all positive predictions</li>
                        <li><strong>Recall:</strong> Ratio of true positives to all actual positives</li>
                        <li><strong>F1-Score:</strong> Harmonic mean balancing precision and recall</li>
                        <li><strong>Processing Time:</strong> Average inference time per image</li>
                    </ul>
                    
                    <img src="images/evaluation-metrics.jpg" alt="Performance comparison across methods" class="content-image">
                    <p class="image-caption">Figure 20: Performance comparison showing Classical CV baseline, CNN, YOLO, and U-Net results.</p>
                    
                    <h3>System Performance Comparison</h3>
                    <table>
                        <thead>
                            <tr>
                                <th>Method</th>
                                <th>Accuracy</th>
                                <th>F1-Score</th>
                                <th>Processing Time</th>
                                <th>Use Case</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>Classical CV</td>
                                <td>78%</td>
                                <td>76%</td>
                                <td>0.1s</td>
                                <td>Pre-screening filter</td>
                            </tr>
                            <tr>
                                <td>CNN Classification</td>
                                <td>89%</td>
                                <td>89%</td>
                                <td>0.3s</td>
                                <td>Feature extraction</td>
                            </tr>
                            <tr>
                                <td><strong>YOLO v8 (Hybrid)</strong></td>
                                <td><strong>92%</strong></td>
                                <td><strong>92%</strong></td>
                                <td><strong>0.2s</strong></td>
                                <td><strong>Optimal balance</strong></td>
                            </tr>
                            <tr>
                                <td>U-Net Segmentation</td>
                                <td>95%</td>
                                <td>95%</td>
                                <td>0.5s</td>
                                <td>Precise boundaries</td>
                            </tr>
                        </tbody>
                    </table>
                    <p><strong>Hybrid system average:</strong> 0.2 seconds per image with 92% accuracy‚Äîachieving optimal speed-accuracy balance.</p>
                    
                    <h3>Per-Defect Type Performance</h3>
                    <p>The system achieves varying accuracy levels across different defect categories based on size and detection difficulty:</p>
                    <table>
                        <thead>
                            <tr>
                                <th>Defect Type</th>
                                <th>Size Range</th>
                                <th>Primary Method</th>
                                <th>Accuracy</th>
                                <th>Difficulty</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>Open Circuits</td>
                                <td>0.1-5mm</td>
                                <td>Edge Detection</td>
                                <td>95%</td>
                                <td>Easy</td>
                            </tr>
                            <tr>
                                <td>Missing Traces</td>
                                <td>Variable</td>
                                <td>Template Matching</td>
                                <td>93%</td>
                                <td>Easy-Moderate</td>
                            </tr>
                            <tr>
                                <td>Short Circuits</td>
                                <td>0.05-2mm</td>
                                <td>Template Matching</td>
                                <td>89%</td>
                                <td>Moderate</td>
                            </tr>
                            <tr>
                                <td>Geometric Errors</td>
                                <td>Variable</td>
                                <td>Width Analysis</td>
                                <td>87%</td>
                                <td>Moderate</td>
                            </tr>
                            <tr>
                                <td>Micro-Cracks</td>
                                <td>10-100 ¬µm</td>
                                <td>Morphological</td>
                                <td>85%</td>
                                <td>Difficult</td>
                            </tr>
                        </tbody>
                    </table>
                    <p><strong>Note:</strong> Open circuits achieve 95%+ accuracy for gaps over 0.2mm with high-contrast imaging.</p>
                </section>

                <section class="content-section">
                    <h2>Key Challenges & Solutions Implemented</h2>
                    <p>The project addressed three main technical limitations through targeted solutions in the hybrid architecture.</p>
                    
                    <h3>1. Lighting Sensitivity</h3>
                    <p><strong>Challenge:</strong> Shadows create false edges, reflections disrupt color segmentation, and lighting variations reduce detection accuracy.</p>
                    <p><strong>Solution:</strong> Deep learning layer (YOLO/U-Net) handles lighting variations that break classical methods. Multi-scale training improves robustness.</p>
                    
                    <h3>2. Alignment Issues</h3>
                    <p><strong>Challenge:</strong> Even 2mm board shifts break template matching. Rotation errors affect geometric measurements. Traditional methods fail with misalignment.</p>
                    <p><strong>Solution:</strong> Multi-scale detection and rotation-invariant features in neural networks. YOLO v8 handles position variations without template dependency.</p>
                    
                    <h3>3. Data Scarcity & Class Imbalance</h3>
                    <p><strong>Challenge:</strong> Defects are rare in production (5-10% of samples), creating severe class imbalance during training.</p>
                    <p><strong>Solution:</strong> Weighted random sampling with inverse frequency weighting. Extensive data augmentation (rotation, flips, brightness, noise). Transfer learning from ImageNet pre-trained backbones.</p>
                    
                    <img src="images/ml-challenges.jpg" alt="Challenges and solutions in PCB defect detection" class="content-image">
                    <p class="image-caption">Figure 21: Key challenges (lighting, alignment, data scarcity) and implemented solutions (hybrid architecture, multi-scale detection, weighted sampling).</p>
                    
                    <h3>Additional Solutions</h3>
                    <ul>
                        <li><strong>Speed Optimization:</strong> Two-stage pipeline filters 80% with fast classical CV (0.1s), reserves expensive ML for complex cases only</li>
                        <li><strong>Cross-Domain Training:</strong> 3 diverse datasets (Tang, TDD-net, Industrial) with multiple lighting conditions</li>
                        <li><strong>Regularization:</strong> Dropout (0.3), weight decay (0.0001), early stopping to prevent overfitting</li>
                    </ul>
                </section>

                <section class="content-section">
                    <h2>Future Work</h2>
                    <p>Next steps focus on deployment optimization, advanced architectures, and expanding detection capabilities.</p>
                    
                    <h3>Deployment & Optimization</h3>
                    <ul>
                        <li><strong>Edge Deployment with ONNX:</strong> Model optimization for deployment on resource-constrained inspection hardware</li>
                        <li><strong>Quantization:</strong> Reduce model size and inference time while maintaining accuracy</li>
                        <li><strong>Hardware Acceleration:</strong> GPU/TPU optimization for real-time processing at scale</li>
                    </ul>
                    
                    <h3>Advanced Model Architectures</h3>
                    <ul>
                        <li><strong>Vision Transformers:</strong> Attention-based models for improved global context understanding</li>
                        <li><strong>Few-Shot Learning:</strong> Rapid adaptation to new defect types with minimal training examples</li>
                        <li><strong>Self-Supervised Learning:</strong> Discover defect patterns without explicit labeling</li>
                    </ul>
                    
                    <h3>Multi-Modal & Distributed Learning</h3>
                    <ul>
                        <li><strong>Multi-Modal Learning:</strong> Combine visual inspection with thermal imaging for subsurface defect detection</li>
                        <li><strong>Federated Learning:</strong> Train models across multiple manufacturing sites while preserving data privacy</li>
                        <li><strong>Continuous Learning:</strong> Systems that automatically improve with production feedback</li>
                    </ul>
                    
                    <h3>Deployment Strategy</h3>
                    <ul>
                        <li><strong>ONNX Conversion:</strong> Cross-platform deployment on edge devices, servers, and cloud infrastructure</li>
                        <li><strong>REST API:</strong> Real-time inference endpoints for integration with existing manufacturing execution systems</li>
                        <li><strong>Batch Processing:</strong> Parallel processing pipelines for offline quality audits</li>
                    </ul>
                </section>


                <section class="content-section">
                    <h2>Project Summary</h2>
                    <p>The hybrid detection system successfully combines classical computer vision with machine learning for accurate real-time PCB defect detection:</p>
                    
                    <div class="defect-summary">
                        <h3>Key Achievements</h3>
                        <ul>
                            <li><strong>Hybrid Architecture:</strong> Two-stage pipeline achieves 92% accuracy at 0.2 seconds average‚Äîoptimal speed-accuracy balance</li>
                            <li><strong>Training Data:</strong> 3,500+ annotated images from 3 benchmark datasets (Tang et al., TDD-net, Industrial)</li>
                            <li><strong>Deep Learning Models:</strong> YOLO v8 (92% accuracy, 0.2s) and U-Net (95% accuracy, 0.5s) with ResNet50/EfficientNet backbones</li>
                            <li><strong>Performance:</strong> 95% accuracy on open circuits, 93% on missing traces, 89% on shorts, 87% on geometric errors, 85% on micro-cracks</li>
                            <li><strong>Speed Optimization:</strong> Classical CV pre-screens 80% of cases in 0.1s, ML handles complex defects only</li>
                            <li><strong>Robustness:</strong> Handles lighting variations and alignment issues that break traditional methods</li>
                        </ul>
                    </div>
                    
                    <h3>Target Audience</h3>
                    <ul>
                        <li><strong>Primary Users:</strong> PCB manufacturers requiring 90%+ accuracy, assembly lines with quality requirements, operations seeking ROI on automated inspection</li>
                        <li><strong>Secondary Users:</strong> Industrial CV/ML engineers, manufacturing automation teams, academic researchers in computer vision</li>
                    </ul>
                    
                    <h3>System Goals Achieved</h3>
                    <ul>
                        <li><strong>Accuracy:</strong> Classical CV baseline 78% ‚úì | YOLO hybrid 92% ‚úì | Open circuits 95%+ for gaps > 0.2mm ‚úì</li>
                        <li><strong>Speed:</strong> Pre-screening 0.1s ‚úì | YOLO 0.2s ‚úì | U-Net 0.5s ‚úì</li>
                        <li><strong>Deployment:</strong> Trained on 3,500+ images ‚úì | ResNet50/EfficientNet backbones ‚úì | ONNX-ready ‚úì</li>
                    </ul>
                </section>

                <div class="navigation-links">
                    <a href="results.html" class="btn btn-secondary">‚Üê Previous: Results & Analysis</a>
                    <a href="interactive.html" class="btn btn-primary">Next: Interactive Demo ‚Üí</a>
                </div>
            </div>
        </div>
    </main>

    <footer class="footer">
        <div class="container">
            <div class="footer-content">
                <div class="footer-section">
                    <h3>PCB Defect Detection Project</h3>
                    <p>Hybrid detection system combining classical computer vision with deep learning for 92% accuracy at 0.2 seconds.</p>
                </div>
                <div class="footer-section">
                    <h4>Quick Links</h4>
                    <ul>
                        <li><a href="intro.html">Introduction</a></li>
                        <li><a href="defects.html">Common Defects</a></li>
                        <li><a href="opencv.html">OpenCV Techniques</a></li>
                        <li><a href="machine-learning.html">Machine Learning</a></li>
                    </ul>
                </div>
                <div class="footer-section">
                    <h4>Resources</h4>
                    <ul>
                        <li><a href="bibliography.html">Bibliography</a></li>
                        <li><a href="https://opencv.org" target="_blank">OpenCV Documentation</a></li>
                        <li><a href="https://github.com" target="_blank">GitHub Repository</a></li>
                    </ul>
                </div>
            </div>
        </div>
    </footer>

    <script src="script.js"></script>
</body>
</html>
